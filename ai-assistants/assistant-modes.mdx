---
title: "Modos do Assistente"
icon: "wave-pulse"
description: "Entenda os três modos de geração de voz disponíveis para seus assistentes de IA e quando utilizar cada um."
---

Os assistentes de IA da **OmniTech IA** podem operar em **três modos distintos de voz**.  
Cada modo define como a fala do usuário é interpretada e como a resposta do assistente é gerada.

<Callout>
A escolha correta do modo pode melhorar o tempo de resposta, a naturalidade da conversa e a experiência geral da chamada.
</Callout>

## 1. Pipeline

| | |
|---|---|
| **Nome na interface** | `Pipeline` |
| **Como funciona** | Fala → Texto (STT) → Modelo de IA (LLM) → Voz (TTS) |
| **Latência** | ~800 – 1500 ms (varia conforme idioma e modelo) |
| **Ideal para** | Raciocínio complexo, prompts dinâmicos, respostas longas |

No modo **Pipeline**, a fala do usuário é primeiro transcrita em texto, processada pelo modelo de linguagem e depois convertida novamente em áudio.  
É um método consolidado que oferece **máxima flexibilidade e controle**:

- Suporta **todas as vozes disponíveis**, incluindo vozes personalizadas e clonadas.
- Ideal para **respostas longas**, explicativas ou em formato de parágrafo.
- Permite que o modelo utilize **variáveis** e contexto anterior de forma precisa.

### Quando escolher Pipeline

1. Quando são necessárias respostas ricas e com múltiplas frases (ex.: suporte técnico, explicações detalhadas).
2. Quando o assistente precisa raciocinar sobre **dados estruturados** ou prompts complexos.
3. Quando é essencial ter controle total da voz utilizada (voz de marca ou clonada).

---

## 2. Speech-to-Speech (Multimodal)

| | |
|---|---|
| **Nome na interface** | `Speech-to-Speech` |
| **Como funciona** | Geração direta **fala → fala**, sem texto intermediário |
| **Latência** | ~300 – 600 ms (ultra baixa) |
| **Ideal para** | Conversas naturais, respostas rápidas e reativas |

No modo **Speech-to-Speech**, não há etapas separadas de transcrição e síntese de voz.  
Um modelo multimodal escuta e responde diretamente em áudio, criando uma experiência mais fluida:

- **Respostas quase instantâneas**, com excelente tempo de reação.
- Entonação mais natural, incluindo pausas e variações de fala.
- Suporte atual a um **conjunto limitado de vozes**, que é ampliado continuamente.

### Quando escolher Speech-to-Speech

1. Quando a conversa precisa ser **rápida e dinâmica** (vendas, confirmações, agendamentos).
2. Quando as respostas são **curtas e objetivas**.
3. Quando não há necessidade de voz personalizada ou clonada.

<Note>
O modo Speech-to-Speech evolui rapidamente.  
Se você precisa de baixa latência **e** voz clonada, utilize o modo **Dualplex**.
</Note>

---

## 3. Dualplex (Beta)

| | |
|---|---|
| **Nome na interface** | `Dualplex` |
| **Como funciona** | Modelo multimodal + LLM com saída de voz via ElevenLabs |
| **Latência** | Baixa (varia conforme voz e modelo) |
| **Ideal para** | Respostas rápidas, naturais e com vozes premium ou de marca (clonadas) |

O modo **Dualplex** combina a velocidade do Speech-to-Speech com a qualidade de voz do **ElevenLabs**, também utilizada no Pipeline.  
O assistente entende a fala do usuário em tempo real e renderiza a resposta final com alta fidelidade de áudio.

- **Alternância de fala quase instantânea**, semelhante ao Speech-to-Speech.
- Acesso à biblioteca de vozes do **ElevenLabs**, incluindo **vozes clonadas**.
- Ideal para respostas **curtas e médias**, com entonação expressiva.
- **Modo recomendado** para a maioria dos casos de uso atuais (em Beta).

### Quando escolher Dualplex

1. Quando você precisa de velocidade **e** voz personalizada ou de marca.
2. Quando deseja respostas expressivas sem abrir mão da identidade sonora.
3. Quando está confortável em utilizar um recurso avançado ainda em **Beta**.

---

## Alternando entre os modos

Você pode selecionar o modo de operação de cada assistente em:  
**Assistente → Configurações → Motor de Voz**.

Recomenda-se testar os três modos para encontrar o melhor equilíbrio entre **velocidade, qualidade de voz e experiência do usuário** para o seu cenário.

---

**Dica prática:**  
Grave chamadas de teste usando modos diferentes e compare a latência percebida e o engajamento do usuário para definir o melhor fluxo.
